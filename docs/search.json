[
  {
    "objectID": "posts/hello/index.html",
    "href": "posts/hello/index.html",
    "title": "1",
    "section": "",
    "text": "hi"
  },
  {
    "objectID": "posts/hello/index.html#greeting-message",
    "href": "posts/hello/index.html#greeting-message",
    "title": "Hello",
    "section": "",
    "text": "To start, let’s write a simple greeting message using Quarto:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "nimwver",
    "section": "",
    "text": "ML 개발자를 목표로 공부하고 있습니다. 하지만 공부하고 있지 않는 시간이 많습니다. 이런!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "web+pyramid",
    "section": "",
    "text": "아이돌 얼굴 인식 시스템 - 1\n\n\n\n\n\n\ncode\n\n\njupyter\n\n\nInsightFace\n\n\n\n\n\n\n\n\n\nJul 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMNIST 숫자 분류\n\n\n\n\n\n\ncode\n\n\njupyter\n\n\n\n\n\n\n\n\n\nMay 25, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hello/index.html#section",
    "href": "posts/hello/index.html#section",
    "title": "1",
    "section": "",
    "text": "hi"
  },
  {
    "objectID": "posts/hello/hello.html",
    "href": "posts/hello/hello.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/hello.html#mnist-load",
    "href": "posts/hello/hello.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/hello/hello.html#데이터-로더",
    "href": "posts/hello/hello.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/hello/hello.html#모델-정의",
    "href": "posts/hello/hello.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/hello/hello.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/hello/hello.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/hello/hello.html#훈련",
    "href": "posts/hello/hello.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/hello/hello.html#결과",
    "href": "posts/hello/hello.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html",
    "href": "posts/hello/MNIST 숫자 분류.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#mnist-load",
    "href": "posts/hello/MNIST 숫자 분류.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#데이터-로더",
    "href": "posts/hello/MNIST 숫자 분류.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#모델-정의",
    "href": "posts/hello/MNIST 숫자 분류.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/hello/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#훈련",
    "href": "posts/hello/MNIST 숫자 분류.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#결과",
    "href": "posts/hello/MNIST 숫자 분류.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html",
    "href": "posts/practice/MNIST 숫자 분류.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#mnist-load",
    "href": "posts/practice/MNIST 숫자 분류.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#데이터-로더",
    "href": "posts/practice/MNIST 숫자 분류.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#모델-정의",
    "href": "posts/practice/MNIST 숫자 분류.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/practice/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#훈련",
    "href": "posts/practice/MNIST 숫자 분류.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#결과",
    "href": "posts/practice/MNIST 숫자 분류.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html",
    "href": "posts/practice/MNIST_ResNet.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에 존재하는 모델을 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 손쉽게 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환(transform)하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n데이터 세트의 시각화 (좌: 훈련 데이터, 우: 테스트 데이터)\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 모두 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 수정할 부분이 거의 없습니다만, 주의할 점이 있다면 MNIST 이미지는 일반적인 이미지와 다르게 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n또한 이 모델은 분류 모델이므로 계층의 마지막 단계에 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n여기선 모델의 구조만을 가지고 오는 것이지만 모델을 처음부터 훈련하는게 아니라 미세 조정(Fine-tuning)을 하고 싶다면, 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 불러와 고정할 수 있도록 모델을 불러오는 과정에서 pretrained 인자를 True, 모델 매개변수의 requires_grad를 False로 설정하면 됩니다. 주석을 참고하세요.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n# model = models.resnet18(pretrained=True) -&gt; 매개변수도 같이 로드\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. 해당 변수는 Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 모델을 훈련시키기 위해선 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 device로 옮깁니다. 이 과정은 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실을 같이 보는 경우도 많고, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 주석을 참고하세요.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 더 이상 개선이 어렵다고 판단되면 적당한 시점에 훈련을 멈추는 것도 좋은 방법입니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. ResNet과 같은 구조적으로 증명된 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#mnist-load",
    "href": "posts/practice/MNIST_ResNet.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환(transform)하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n데이터 세트의 시각화 (좌: 훈련 데이터, 우: 테스트 데이터)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#데이터-로더",
    "href": "posts/practice/MNIST_ResNet.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 모두 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#모델-정의",
    "href": "posts/practice/MNIST_ResNet.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 수정할 부분이 거의 없습니다만, 주의할 점이 있다면 MNIST 이미지는 일반적인 이미지와 다르게 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n또한 이 모델은 분류 모델이므로 계층의 마지막 단계에 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n여기선 모델의 구조만을 가지고 오는 것이지만 모델을 처음부터 훈련하는게 아니라 미세 조정(Fine-tuning)을 하고 싶다면, 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 불러와 고정할 수 있도록 모델을 불러오는 과정에서 pretrained 인자를 True, 모델 매개변수의 requires_grad를 False로 설정하면 됩니다. 주석을 참고하세요.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n# model = models.resnet18(pretrained=True) -&gt; 매개변수도 같이 로드\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/practice/MNIST_ResNet.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. 해당 변수는 Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 모델을 훈련시키기 위해선 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 device로 옮깁니다. 이 과정은 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#훈련",
    "href": "posts/practice/MNIST_ResNet.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실을 같이 보는 경우도 많고, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 주석을 참고하세요.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 더 이상 개선이 어렵다고 판단되면 적당한 시점에 훈련을 멈추는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#결과",
    "href": "posts/practice/MNIST_ResNet.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. ResNet과 같은 구조적으로 증명된 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html",
    "href": "posts/face-detection_1/face-detection_01.html",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "얼굴 인식은 사람의 얼굴 특징을 식별하고 분석하여 개인을 고유하게 식별하는 데 사용되는 기술입니다. 주로 컴퓨터 비전과 패턴 인식 기술을 기반으로 하며, 광학적 또는 사진 기법을 통해 사진이나 비디오에서 얼굴을 감지하고 분석합니다. 보안 시스템, 사용자 인증, 의료, 마케팅 등 다양한 분야에서 활용되는 등, 가능성 또한 광범위합니다.\n이 글에서는 이처럼 여러 측면에서 활용 가능한 얼굴 인식 시스템을 만들고 탐구해봅니다. 이 포스트에서는 케이팝 아이돌 Aespa 4명, NewJeans의 5명의 멤버들 총 9명의 얼굴을 이미지 내에서 탐지하고 인식하는 과정을 소개하겠습니다.\n\n\n시스템에 필요한 데이터를 수집하는 것이 첫 번째 과정입니다. 저는 Pinterest에서 각 인물 당 이미지 약 200장 정도를 저장했습니다. 이 부분은 프로그래밍으로 하지 않고 WFDownloader라는 프로그램을 사용해 이미지 벌크를 보다 쉽게 다운로드 할 수 있었습니다. 이미지 검증 과정이 부족할 관계로 이미지의 명확성을 위해 ’그룹 이름 + 멤버 이름’으로 검색합니다.\n\n\n\n파이썬으로 얼굴을 감지하는 모듈에는 여러 가지가 있고, 이들 모두 쉽게 활용할 수 있습니다. 저는 그 중 MTCNN, Dlib, InsightFace 3가지를 비교해 보았습니다. 3개 모두 파이썬 패키지 외에 별 다른 설치 없이 사용할 수 있습니다.\n\n수집한 이미지 데이터들 중 무작위로 선택한 이미지에서 각각 얼굴을 찾아내고 이를 시각적으로 비교해 보았습니다. \n일부 이미지에서 다음과 같이 성능의 차이를 보입니다. 걸그룹 특성 상, 셀피가 많고 이 경우엔 카메라 각도가 일반적이지 않은 관계로 정교하지 못한 모델은 생각보다 얼굴 감지에 어려움이 있는 듯 했습니다. 따라서 가장 성능이 뛰어난 RetinaFace를 사용하겠습니다.\n사실 RetinaFace는 많은 경우에 현재까지도 정확도와 속도 측면에서 최고 수준의 성능(State-of-the-art)을 달성하고 있습니다. 특히 다양한 크기와 방향의 얼굴을 처리하는 데에 강점을 가지고 있어 시스템의 목적에도 알맞은 모델이기도 합니다. 다만 딥 러닝 모델인 만큼 어느 정도의 부하가 있습니다.\n아래는 RetinaFace를 이용한 얼굴 감지 결과입니다. \n\n\n\n얼굴을 인식하기 위해서는 얼굴 이미지를 학습 시켜야 합니다. 하지만 이 전에 수집한 이미지로는 이미지에 얼굴 만이 아닌 다른 요소가 많기 때문에 제대로 학습 시킬 수 없습니다.\n이 때문에 얼굴 감지가 필요한 것입니다. 얼굴 감지를 사용하여 얼굴을 중심으로 이미지를 잘라 저장합니다.\n\n이때 얼굴이 2개 이상일 때는 cv2의 Laplacian 메소드를 이용해 감지된 얼굴의 선명도를 비교하고 기준 이상 다를 경우 선명한 얼굴만을 잘라내고, 비슷할 경우엔 해당 이미지를 버리는 방식으로 처리했습니다. 이는 사진의 주인공이 흐릿하게 나올 시에는 부정확하게 처리 될 수도 있다는 점에서 개선이 필요합니다.\n잘라낸 이미지들의 일부는 다음과 같습니다. \n훈련할 모델은 이미지 처리에 특화된 ResNet-50입니다. 이 때문에 훈련을 위해서 행해야 할 전처리 과정은\n\n이미지의 크기를 224 x 224로 조정\n정규화\n데이터의 이미지와 레이블을 (X, Y)로 나누고\n8:1:1 비율로 train, validatoin, test 데이터 셋을 나눕니다.\n\n코드는 아래와 같습니다.\n\n데이터 셋의 크기가 작은 만큼 데이터 증강(Data Augmentation)도 도움이 될 것입니다.\n\n\n\n훈련에 필요한 손실 함수는 Cross Entropy Loss을, 최적화 함수는 Adam을 사용하겠습니다. 훈련 전에 ResNet-50을 로드하고 출력 계층을 카테고리의 길이와 같이 설정하는 것을 잊지 마세요. 제 경우엔 출력 계층의 크기, 곧 len(categories)는 9가 됩니다.\n\n\n100%|██████████| 20/20 [05:29&lt;00:00, 16.49s/it] Validation Loss: 0.8527, Validation Accuracy: 0.8111\n\n80% 정도의 정확도를 확인할 수 있습니다.\n\n\n\nConfusion Matrix를 통해 테스트 셋에서의 정확도를 확인해 보겠습니다. \n언뜻 보기에는 모델의 정확도에는 문제가 없어 보입니다. 실제 사진에 모델로 예측해본다면 어떨까요? 예를 들어 얼굴이 두 개 있는 새로운 사진 말입니다.\n이는 1. 모델을 불러오고, 2. 이미지에서 얼굴을 감지한 후, 3. 얼굴 이미지를 모델이 처리할 수 있는 형태로 transform(정규화, 텐서화 등) 하면, 4. 모델이 해당 이미지의 예측 결과를 출력하는 순서로 진행됩니다.\n\n\n\n두 분 다 지젤 씨가 아니다.\n\n\n확인 결과 이 외의 사진에서도 대부분의 사람을 한 사람으로 예측하는 등 정확도가 크게 떨어지는 것으로 나타났습니다. 본 적 없는 사진에 대해서 낮은 정확도를 보여주는 듯 합니다.\n\n\n\n9명의 이미지를 어느 정도는 식별하는 데 성공했지만, 모델의 단순성에 비해 사용자 정의에 대한 유연성이 떨어지기 때문에 제공한 톤 앤 매너가 비슷한 아이돌의 사진은 구분하기 힘들어 하는 모습을 보입니다. 따라서 저는 다른 방법을 통해 얼굴 인식 시스템을 만들어 보도록 하겠습니다.\n이어서 얼굴 인식에 최적화된 InsightFace를 통해 얼굴에서 임베딩을 추출하고 이를 통해 유사한 얼굴을 인식하는 조금 더 나은 모델을 만들어 보겠습니다.\n읽어주셔서 감사합니다.\nCiao!\n\n\n\nNBA Face Recognition System using InsightFace - Yongsun Yoon\nInsightFace"
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#데이터",
    "href": "posts/face-detection_1/face-detection_01.html#데이터",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "시스템에 필요한 데이터를 수집하는 것이 첫 번째 과정입니다. 저는 Pinterest에서 각 인물 당 이미지 약 200장 정도를 저장했습니다. 이 부분은 프로그래밍으로 하지 않고 WFDownloader라는 프로그램을 사용해 이미지 벌크를 보다 쉽게 다운로드 할 수 있었습니다. 이미지 검증 과정이 부족할 관계로 이미지의 명확성을 위해 ’그룹 이름 + 멤버 이름’으로 검색합니다."
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#얼굴-감지-단계",
    "href": "posts/face-detection_1/face-detection_01.html#얼굴-감지-단계",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "파이썬으로 얼굴을 감지하는 모듈에는 여러 가지가 있고, 이들 모두 쉽게 활용할 수 있습니다. 저는 그 중 MTCNN, Dlib, InsightFace 3가지를 비교해 보았습니다. 3개 모두 파이썬 패키지 외에 별 다른 설치 없이 사용할 수 있습니다.\n\n수집한 이미지 데이터들 중 무작위로 선택한 이미지에서 각각 얼굴을 찾아내고 이를 시각적으로 비교해 보았습니다. \n일부 이미지에서 다음과 같이 성능의 차이를 보입니다. 걸그룹 특성 상, 셀피가 많고 이 경우엔 카메라 각도가 일반적이지 않은 관계로 정교하지 못한 모델은 생각보다 얼굴 감지에 어려움이 있는 듯 했습니다. 따라서 가장 성능이 뛰어난 RetinaFace를 사용하겠습니다.\n사실 RetinaFace는 많은 경우에 현재까지도 정확도와 속도 측면에서 최고 수준의 성능(State-of-the-art)을 달성하고 있습니다. 특히 다양한 크기와 방향의 얼굴을 처리하는 데에 강점을 가지고 있어 시스템의 목적에도 알맞은 모델이기도 합니다. 다만 딥 러닝 모델인 만큼 어느 정도의 부하가 있습니다.\n아래는 RetinaFace를 이용한 얼굴 감지 결과입니다."
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#참조",
    "href": "posts/face-detection_1/face-detection_01.html#참조",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "NBA Face Recognition System using InsightFace - Yongsun Yoon\nInsightFace"
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#이미지-전처리",
    "href": "posts/face-detection_1/face-detection_01.html#이미지-전처리",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "얼굴을 인식하기 위해서는 얼굴 이미지를 학습 시켜야 합니다. 하지만 이 전에 수집한 이미지로는 이미지에 얼굴 만이 아닌 다른 요소가 많기 때문에 제대로 학습 시킬 수 없습니다.\n이 때문에 얼굴 감지가 필요한 것입니다. 얼굴 감지를 사용하여 얼굴을 중심으로 이미지를 잘라 저장합니다.\n\n이때 얼굴이 2개 이상일 때는 cv2의 Laplacian 메소드를 이용해 감지된 얼굴의 선명도를 비교하고 기준 이상 다를 경우 선명한 얼굴만을 잘라내고, 비슷할 경우엔 해당 이미지를 버리는 방식으로 처리했습니다. 이는 사진의 주인공이 흐릿하게 나올 시에는 부정확하게 처리 될 수도 있다는 점에서 개선이 필요합니다.\n잘라낸 이미지들의 일부는 다음과 같습니다. \n훈련할 모델은 이미지 처리에 특화된 ResNet-50입니다. 이 때문에 훈련을 위해서 행해야 할 전처리 과정은\n\n이미지의 크기를 224 x 224로 조정\n정규화\n데이터의 이미지와 레이블을 (X, Y)로 나누고\n8:1:1 비율로 train, validatoin, test 데이터 셋을 나눕니다.\n\n코드는 아래와 같습니다.\n\n데이터 셋의 크기가 작은 만큼 데이터 증강(Data Augmentation)도 도움이 될 것입니다."
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#훈련",
    "href": "posts/face-detection_1/face-detection_01.html#훈련",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "훈련에 필요한 손실 함수는 Cross Entropy Loss을, 최적화 함수는 Adam을 사용하겠습니다. 훈련 전에 ResNet-50을 로드하고 출력 계층을 카테고리의 길이와 같이 설정하는 것을 잊지 마세요. 제 경우엔 출력 계층의 크기, 곧 len(categories)는 9가 됩니다.\n\n\n100%|██████████| 20/20 [05:29&lt;00:00, 16.49s/it] Validation Loss: 0.8527, Validation Accuracy: 0.8111\n\n80% 정도의 정확도를 확인할 수 있습니다."
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#평가",
    "href": "posts/face-detection_1/face-detection_01.html#평가",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "Confusion Matrix를 통해 테스트 셋에서의 정확도를 확인해 보겠습니다. \n언뜻 보기에는 모델의 정확도에는 문제가 없어 보입니다. 실제 사진에 모델로 예측해본다면 어떨까요? 예를 들어 얼굴이 두 개 있는 새로운 사진 말입니다.\n이는 1. 모델을 불러오고, 2. 이미지에서 얼굴을 감지한 후, 3. 얼굴 이미지를 모델이 처리할 수 있는 형태로 transform(정규화, 텐서화 등) 하면, 4. 모델이 해당 이미지의 예측 결과를 출력하는 순서로 진행됩니다.\n\n\n\n두 분 다 지젤 씨가 아니다.\n\n\n확인 결과 이 외의 사진에서도 대부분의 사람을 한 사람으로 예측하는 등 정확도가 크게 떨어지는 것으로 나타났습니다. 본 적 없는 사진에 대해서 낮은 정확도를 보여주는 듯 합니다."
  },
  {
    "objectID": "posts/face-detection_1/face-detection_01.html#결론",
    "href": "posts/face-detection_1/face-detection_01.html#결론",
    "title": "아이돌 얼굴 인식 시스템 - 1",
    "section": "",
    "text": "9명의 이미지를 어느 정도는 식별하는 데 성공했지만, 모델의 단순성에 비해 사용자 정의에 대한 유연성이 떨어지기 때문에 제공한 톤 앤 매너가 비슷한 아이돌의 사진은 구분하기 힘들어 하는 모습을 보입니다. 따라서 저는 다른 방법을 통해 얼굴 인식 시스템을 만들어 보도록 하겠습니다.\n이어서 얼굴 인식에 최적화된 InsightFace를 통해 얼굴에서 임베딩을 추출하고 이를 통해 유사한 얼굴을 인식하는 조금 더 나은 모델을 만들어 보겠습니다.\n읽어주셔서 감사합니다.\nCiao!"
  }
]