[
  {
    "objectID": "posts/hello/index.html",
    "href": "posts/hello/index.html",
    "title": "1",
    "section": "",
    "text": "hi"
  },
  {
    "objectID": "posts/hello/index.html#greeting-message",
    "href": "posts/hello/index.html#greeting-message",
    "title": "Hello",
    "section": "",
    "text": "To start, let’s write a simple greeting message using Quarto:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "nimwver",
    "section": "",
    "text": "ML 개발자를 목표로 공부하고 있습니다. 하지만 공부하고 있지 않는 시간이 많습니다. 이런!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "web+pyramid",
    "section": "",
    "text": "MNIST 숫자 분류\n\n\n\n\n\n\ncode\n\n\njupyter\n\n\n\n\n\n\n\n\n\nMay 25, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hello/index.html#section",
    "href": "posts/hello/index.html#section",
    "title": "1",
    "section": "",
    "text": "hi"
  },
  {
    "objectID": "posts/hello/hello.html",
    "href": "posts/hello/hello.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/hello.html#mnist-load",
    "href": "posts/hello/hello.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/hello/hello.html#데이터-로더",
    "href": "posts/hello/hello.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/hello/hello.html#모델-정의",
    "href": "posts/hello/hello.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/hello/hello.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/hello/hello.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/hello/hello.html#훈련",
    "href": "posts/hello/hello.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/hello/hello.html#결과",
    "href": "posts/hello/hello.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html",
    "href": "posts/hello/MNIST 숫자 분류.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#mnist-load",
    "href": "posts/hello/MNIST 숫자 분류.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#데이터-로더",
    "href": "posts/hello/MNIST 숫자 분류.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#모델-정의",
    "href": "posts/hello/MNIST 숫자 분류.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/hello/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#훈련",
    "href": "posts/hello/MNIST 숫자 분류.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/hello/MNIST 숫자 분류.html#결과",
    "href": "posts/hello/MNIST 숫자 분류.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html",
    "href": "posts/practice/MNIST 숫자 분류.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에서 불러온 모델을 머신러닝에서 가장 유명한 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#mnist-load",
    "href": "posts/practice/MNIST 숫자 분류.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#데이터-로더",
    "href": "posts/practice/MNIST 숫자 분류.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 전부 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#모델-정의",
    "href": "posts/practice/MNIST 숫자 분류.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 주의할 점은 MNIST 이미지는 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 한다는 것입니다. 또한 이 모델은 분류 모델이므로 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n미세 조정(Fine-tuning)을 하고 싶다면 모델을 불러오는 과정에서 pretrained 인자를 True로 하고 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 고정할 수 있게 모델 매개변수의 requires_grad를 False로 바꿔주면 되니 참고하시기 바랍니다.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/practice/MNIST 숫자 분류.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 훈련시키기 위해서는 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 옮깁니다. 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#훈련",
    "href": "posts/practice/MNIST 숫자 분류.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실도 같이 보는 경우도 많지만, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 손실을 구하는 방법은 주석으로 달아놨으니 참고하시면 되겠습니다.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 적당한 시점에 훈련을 멈추는 것도 괜찮습니다."
  },
  {
    "objectID": "posts/practice/MNIST 숫자 분류.html#결과",
    "href": "posts/practice/MNIST 숫자 분류.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. 기초부터 만드는 방법도 있지만 ResNet과 같은 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html",
    "href": "posts/practice/MNIST_ResNet.html",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "PyTorch에 존재하는 모델을 MNIST 손글씨 숫자 데이터 세트의 숫자를 올바르게 분류하는 모델로 손쉽게 만들어 봅니다.\n\n\nMNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환(transform)하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n데이터 세트의 시각화 (좌: 훈련 데이터, 우: 테스트 데이터)\n\n\n\n\n\n\n\n훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 모두 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)\n\n\n\n\n다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 수정할 부분이 거의 없습니다만, 주의할 점이 있다면 MNIST 이미지는 일반적인 이미지와 다르게 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n또한 이 모델은 분류 모델이므로 계층의 마지막 단계에 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n여기선 모델의 구조만을 가지고 오는 것이지만 모델을 처음부터 훈련하는게 아니라 미세 조정(Fine-tuning)을 하고 싶다면, 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 불러와 고정할 수 있도록 모델을 불러오는 과정에서 pretrained 인자를 True, 모델 매개변수의 requires_grad를 False로 설정하면 됩니다. 주석을 참고하세요.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n# model = models.resnet18(pretrained=True) -&gt; 매개변수도 같이 로드\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n\n\n\n손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. 해당 변수는 Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 모델을 훈련시키기 위해선 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 device로 옮깁니다. 이 과정은 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n\n\n\n훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실을 같이 보는 경우도 많고, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 주석을 참고하세요.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 더 이상 개선이 어렵다고 판단되면 적당한 시점에 훈련을 멈추는 것도 좋은 방법입니다.\n\n\n\n\nmodel.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. ResNet과 같은 구조적으로 증명된 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#mnist-load",
    "href": "posts/practice/MNIST_ResNet.html#mnist-load",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "MNIST 손글씨 숫자 데이터 세트를 불러오는 방법에는 여러 가지가 있습니다. 간단한 방법으로는 Keras나 TensorFlow-datasets, Scikit-Learn을 통해 로드하는 방법 등이 있지만, 그래도 가장 쉬운건 역시 직접 다운로드하는 방법입니다.\n여기선 가장 일반적인 방법은 아니지만 torchvision을 통해 데이터 세트를 다운로드하도록 하겠습니다. 참고로 해당 코드에서는 이 후 PyTorch 사용을 위해 데이터 세트는 다운로드와 동시에 텐서로 변환(transform)하겠습니다.\n\nfrom torchvision import datasets, transforms\n\ndef load_mnist(root='./data', download=True, transform=transforms.ToTensor()):\n    return (\n        datasets.MNIST(root=root, train=True, download=download, transform=transform),\n        datasets.MNIST(root=root, train=False, download=download, transform=transform)\n    )\n\nmnist_train, mnist_test = load_mnist()\n\n로드된 이미지는 다음과 같이 확인할 수 있습니다. 훈련 세트와 테스트 세트 각 첫 번째 이미지를 확인해 보겠습니다.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nim_trn,lb_trn = mnist_train[0]\nim_tst,lb_tst = mnist_test[0]\n\n# 시각화를 위해 텐서를 28x28 numpy배열로 재변환\nim_trn = im_trn.numpy().reshape(28, 28)\nim_tst = im_tst.numpy().reshape(28, 28)\n\nfig, axs = plt.subplots(1, 2, figsize=(4, 2))\n\naxs[0].imshow(im_trn, cmap='gray')\naxs[0].set_title(lb_trn)\n\naxs[1].imshow(im_tst, cmap='gray')\naxs[1].set_title(lb_tst)\n\nfor ax in axs:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n데이터 세트의 시각화 (좌: 훈련 데이터, 우: 테스트 데이터)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#데이터-로더",
    "href": "posts/practice/MNIST_ResNet.html#데이터-로더",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 세트와 검증 세트를 분리한 후, 훈련 시 데이터들을 불러오는 데이터 로더를 정의해 보겠습니다. 훈련 데이터 세트의 80%를 훈련 세트인 dls로, 나머지를 하나의 에포크가 끝난 후 평가하는 val_dls로 분리합니다. 테스트 데이터 세트는 모델의 마지막 평가를 위해 남겨둡니다. 모두 PyTorch의 모듈을 이용합니다.\n참고로 배치 사이즈는 2의 지수 형태가 일반적이라고 하네요.\n\nfrom torch.utils.data import DataLoader, random_split\n\nbatch_size = 128\ntrain_size = int(0.8 * len(mnist_train))\nval_size = len(mnist_train) - train_size\n\ntrain_dataset, val_dataset = random_split(mnist_train, [train_size, val_size])\n\ndls = DataLoader(dataset=train_dataset,\n                 batch_size=batch_size,\n                 shuffle=True,\n                 drop_last=True)\n\nval_dls = DataLoader(dataset=val_dataset,\n                     batch_size=batch_size,\n                     shuffle=True,\n                     drop_last=True)\n\ntst_dls = DataLoader(dataset=mnist_test,\n                     batch_size=batch_size,\n                     shuffle=False)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#모델-정의",
    "href": "posts/practice/MNIST_ResNet.html#모델-정의",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "다음은 torchvision의 models 모듈을 통해 모델(‘ResNet-18’)을 정의합니다. 수정할 부분이 거의 없습니다만, 주의할 점이 있다면 MNIST 이미지는 일반적인 이미지와 다르게 흑백(grayscale) 이미지이기 때문에 이미지 입력 레이어의 채널이 3(RGB)이 아닌 1이 되어야 합니다.\n\n\nOriginal: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nAfter: Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n\n또한 이 모델은 분류 모델이므로 계층의 마지막 단계에 출력의 종류를 정의하는 선형 레이어를 추가해야합니다.\n\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)\n\n여기선 모델의 구조만을 가지고 오는 것이지만 모델을 처음부터 훈련하는게 아니라 미세 조정(Fine-tuning)을 하고 싶다면, 이미 학습된 모델의 가중치와 편향 등의 매개변수(parameter)를 불러와 고정할 수 있도록 모델을 불러오는 과정에서 pretrained 인자를 True, 모델 매개변수의 requires_grad를 False로 설정하면 됩니다. 주석을 참고하세요.\n\nimport torch\nfrom torchvision import models\n\nn_classes = 10\n\nmodel = models.resnet18(pretrained=False)\n# model = models.resnet18(pretrained=True) -&gt; 매개변수도 같이 로드\n\n# 미세 조정 시 모델의 매개변수를 고정(freeze)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# 모델의 첫 번째 계층을 수정\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# 출력 계층 수정\nmodel.fc = torch.nn.Linear(model.fc.in_features, n_classes)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#손실-함수와-최적화-함수-cuda",
    "href": "posts/practice/MNIST_ResNet.html#손실-함수와-최적화-함수-cuda",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "손실 함수와 최적화 함수를 정의합니다. 손실 함수는 분류 모델에 쓰이는 Cross Entropy Loss를 사용하고, 최적화 함수엔 Adam을 사용합니다. 스케줄러를 통해 최적화 함수의 속도를 조절합니다. 5 에포크마다 학습률에 감마(0.1)값을 곱합니다.\n\ncriterion = torch.nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 15\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\n\nGPU 설정을 위해 device 변수를 정의합니다. 해당 변수는 Nvidia GPU를 사용할 수 있는 환경이라면 ’cuda’를, 그 외에는 ’cpu’를 사용합니다. GPU에서 모델을 훈련시키기 위해선 훈련에 필요한 모든 변수를 GPU로 이동시켜야 합니다. 이를 위해 .to(device)를 사용해 모델을 device로 옮깁니다. 이 과정은 아래 훈련 부분에서도 반복하여 사용됩니다.\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)"
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#훈련",
    "href": "posts/practice/MNIST_ResNet.html#훈련",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "훈련 루프를 작성합니다. train 모드와 eval 모드로 나누어 한 에포크의 훈련이 끝날 때 마다 검증 세트로 성능을 평가합니다. 설정한 에포크 수 만큼 훈련합니다.\n성능 평가 시엔 손실을 같이 보는 경우도 많고, 이를 확인하는 방법 또한 정확도 계산과 크게 차이가 없습니다. 주석을 참고하세요.\n\nfor epoch in range(n_epochs):\n    \n    model.train() # 모델 훈련\n    # loss_epoch = 0. -&gt; 손실 계산\n    for inputs, labels in dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optim.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optim.step()\n\n        # loss_epoch += loss.item()\n\n    # avg_loss = loss_epoch / len(dls) -&gt; 에포크 당 평균 손실\n\n    model.eval() # 모델 평가\n    with torch.no_grad():\n        total = 0\n        correct = 0\n        for inputs, labels in val_dls:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch: {epoch}, Accuracy on validation set: {100. * correct / total:.2f}')\n\nEpoch: 0, Accuracy on validation set: 96 %\nEpoch: 1, Accuracy on validation set: 97 %\nEpoch: 2, Accuracy on validation set: 98 %\nEpoch: 3, Accuracy on validation set: 98 %\nEpoch: 4, Accuracy on validation set: 97 %\nEpoch: 5, Accuracy on validation set: 98 %\nEpoch: 6, Accuracy on validation set: 98 %\nEpoch: 7, Accuracy on validation set: 98 %\nEpoch: 8, Accuracy on validation set: 98 %\nEpoch: 9, Accuracy on validation set: 98 %\nEpoch: 10, Accuracy on validation set: 98 %\nEpoch: 11, Accuracy on validation set: 98 %\n\n\nKeyboardInterrupt: \n\n\n정확도를 확인하며 더 이상 개선이 어렵다고 판단되면 적당한 시점에 훈련을 멈추는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/practice/MNIST_ResNet.html#결과",
    "href": "posts/practice/MNIST_ResNet.html#결과",
    "title": "MNIST 숫자 분류",
    "section": "",
    "text": "model.eval()\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for inputs, labels in tst_dls:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\naccuracy = 100. * total_correct / total_samples\nprint(f'Accuracy on test set: {accuracy}%')\n\nAccuracy on test set: 99.13%\n\n\n테스트 세트 기준, 이 모델은 99% 정도의 정확도로 MNIST 데이터 셋을 올바르게 분류할 수 있는 것을 확인할 수 있었습니다.\n\n이렇게 비교적 간단한 방법으로 MNIST 손글씨 숫자 데이터 셋을 분류하는 모델을 만들어 봤습니다. ResNet과 같은 구조적으로 증명된 모델을 사용하면 시간을 크게 들이지 않고 정확도가 높은 모델을 만들어 낼 수 있습니다.\n다음 시간에도 엔지니어링 관점에서 머신러닝을 잘 활용할 수 있는 포스트로 만나뵙겠습니다.\nCiao!"
  }
]